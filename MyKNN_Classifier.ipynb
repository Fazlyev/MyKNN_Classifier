{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Моя реализация алгоритма KNN для бинарной классификации\n",
        "\n",
        "Импортируем необходимые библиотеки для создания класса и для сравнения результатов предсказания с встроенной в sklearn моделью."
      ],
      "metadata": {
        "id": "nXnPcoxFN7Bg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.neighbors import KNeighborsClassifier"
      ],
      "metadata": {
        "id": "kHTnG7ngAEiU"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Данная модель принимает на вход следующие параметры:\n",
        "\n",
        "k - заданное число ближайших соседей, на основании которых происходит классификация. По умолчанию: 3\n",
        "\n",
        "metric - метрика, использующаяся для расчета расстояния между объектами. Доступные значения: 'euclidean', 'manhattan', 'chebyshev', 'cosine' - Евклидова, Манхеттена, Чебышева и косинусная соответственно. По умолчанию: 'euclidean'\n",
        "\n",
        "weight - система взвешивания ближайших соседей. Доступные вариации: 'uniform', 'rank', 'distance' - равномерное, ранговое и по расстоянию соответственно. По умолчанию: uniform"
      ],
      "metadata": {
        "id": "aWJodHhQOGKL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MyKNNClf поддерживает следующие методы:\n",
        "\n",
        "fit(X: pd.DataFrame(), y: pd.Series()) - обучение модели, где X - признаки, а y - классы объектов\n",
        "\n",
        "predict(X) - предсказывает значения классов по признакам\n",
        "\n",
        "prefict_proba(X) - предсказывает вероятности того, что объект относится к классу 1\n"
      ],
      "metadata": {
        "id": "zD4qiwRVO6CA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "MrJe4Bej4W4-"
      },
      "outputs": [],
      "source": [
        "class MyKNNClf:\n",
        "  def __init__(self, k=3, metric = 'euclidean', weight='uniform'):\n",
        "    self.k = k\n",
        "    self.train_size = (0, 0)\n",
        "    self.metric = metric\n",
        "    self.weight = weight\n",
        "\n",
        "  def __str__(self):\n",
        "    return f'MyKNNClf class: k={self.k}'\n",
        "\n",
        "  def fit(self, X: pd.DataFrame(), y: pd.Series()):\n",
        "    self.X = np.array(X)\n",
        "    self.y = np.array(y)\n",
        "    self.train_size = X.shape\n",
        "\n",
        "  def predict(self, X: pd.DataFrame):\n",
        "    y_train = np.array(self.y)#[:, np.newaxis]\n",
        "    X_train = self.X\n",
        "\n",
        "    if self.metric == 'euclidean':\n",
        "      distances = np.sum((np.array(X_train) - np.array(X)[:, np.newaxis])**2, axis=2)**0.5\n",
        "    elif self.metric == 'manhattan':\n",
        "      distances = np.sum(abs(np.array(X_train) - np.array(X)[:, np.newaxis]), axis=2)\n",
        "    elif self.metric == 'chebyshev':\n",
        "      distances = np.max(abs(np.array(X_train) - np.array(X)[:, np.newaxis]), axis=2)\n",
        "    elif self.metric == 'cosine':\n",
        "      distances = 1 - np.sum(np.array(X_train)*np.array(X)[:, np.newaxis], axis=2)/np.sum((np.array(X_train))**2, axis=1)**0.5/np.sum((np.array(X))**2, axis=1)[:, np.newaxis]**0.5\n",
        "\n",
        "    y_pred = []\n",
        "    if self.weight == 'uniform':\n",
        "      class_indexes = np.argsort(distances, axis=1)[:, :self.k]\n",
        "      k_nearest_classes = np.squeeze(y_train[class_indexes])\n",
        "      y_pred = []\n",
        "      for i in range(len(class_indexes)):\n",
        "            y_pred.append(int(np.mean(k_nearest_classes[i])>=0.5))\n",
        "      y_pred = np.array(y_pred)\n",
        "\n",
        "    elif self.weight == 'rank':\n",
        "      class_indexes = np.argsort(distances, axis=1)[:, :self.k] #индексы ближайших соседей по возрастанию, фактически мы можем просто каждому из этих индексов по порядку присвоить номер от 1 до n\n",
        "      nearest_classes = (y_train[class_indexes]==1)\n",
        "      self.nearest_classes = nearest_classes\n",
        "      ranks = np.ones(class_indexes.shape)+np.arange(class_indexes.shape[1])\n",
        "      self.ranks = ranks\n",
        "      for i in range(len(nearest_classes)):\n",
        "        y_pred.append(np.sum(1/ranks[i][np.squeeze(nearest_classes)[i]])/np.sum(1/np.arange(1, nearest_classes.shape[1]+1)))\n",
        "      y_pred = (np.array(y_pred)>=0.5).astype(int)\n",
        "\n",
        "    elif self.weight == 'distance':\n",
        "      class_indexes = np.argsort(distances, axis=1)[:, :self.k] # индексы ближайших k соседей к каждому из 250 элементов\n",
        "      y_pred = []\n",
        "\n",
        "      for i in range(len(class_indexes)):\n",
        "        dist = distances[i]\n",
        "        indexes = class_indexes[i]\n",
        "        weights = 1/(dist[indexes]+1e-6) #веса для каждого из k соседей, расположенных в порядке возрастания\n",
        "        y_pred.append(np.sum(weights*y_train[indexes])/np.sum(weights)) # каждый из этих соседей равен 0 либо 1. Если 1, то вес будет учтен при умножении, иначе нет.\n",
        "      y_pred = (np.array(y_pred)>=0.5).astype(int)\n",
        "\n",
        "\n",
        "    return y_pred\n",
        "\n",
        "  def predict_proba(self, X: pd.DataFrame):\n",
        "    y_train = np.array(self.y)#[:, np.newaxis]\n",
        "    X_train = self.X\n",
        "    y_pred = []\n",
        "\n",
        "    if self.metric == 'euclidean':\n",
        "      distances = np.sum((np.array(X_train) - np.array(X)[:, np.newaxis])**2, axis=2)**0.5\n",
        "    elif self.metric == 'manhattan':\n",
        "      distances = np.sum(abs(np.array(X_train) - np.array(X)[:, np.newaxis]), axis=2)\n",
        "    elif self.metric == 'chebyshev':\n",
        "      distances = np.max(abs(np.array(X_train) - np.array(X)[:, np.newaxis]), axis=2)\n",
        "    elif self.metric == 'cosine':\n",
        "      distances = 1 - np.sum(np.array(X_train)*np.array(X)[:, np.newaxis], axis=2)/np.sum((np.array(X_train))**2, axis=1)**0.5/np.sum((np.array(X))**2, axis=1)[:, np.newaxis]**0.5\n",
        "\n",
        "    if self.weight == 'uniform':\n",
        "      class_indexes = np.argsort(distances, axis=1)[:, :self.k]\n",
        "      k_nearest_classes = np.squeeze(y_train[class_indexes])\n",
        "      for i in range(len(k_nearest_classes)):\n",
        "            y_pred.append(np.mean(k_nearest_classes[i]))\n",
        "      y_pred = np.array(y_pred)\n",
        "\n",
        "    elif self.weight == 'rank':\n",
        "      class_indexes = np.argsort(distances, axis=1)[:, :self.k] #индексы ближайших соседей по возрастанию, фактически мы можем просто каждому из этих индексов по порядку присвоить номер от 1 до n\n",
        "      nearest_classes = (y_train[class_indexes]==1)\n",
        "      ranks = np.ones(class_indexes.shape)+np.arange(class_indexes.shape[1])\n",
        "      for i in range(len(nearest_classes)):\n",
        "        y_pred.append(np.sum(1/ranks[i][np.squeeze(nearest_classes)[i]])/np.sum(1/np.arange(1, nearest_classes.shape[1]+1)))\n",
        "      y_pred = np.array(y_pred)\n",
        "\n",
        "    elif self.weight == 'distance':\n",
        "      class_indexes = np.argsort(distances, axis=1)[:, :self.k] # индексы ближайших k соседей к каждому из 250 элементов\n",
        "      y_pred = []\n",
        "      for i in range(len(class_indexes)):\n",
        "        dist = distances[i]\n",
        "        indexes = class_indexes[i]\n",
        "        weights = 1/(dist[indexes]+1e-6) #веса для каждого из k соседей, расположенных в порядке возрастания\n",
        "        y_pred.append(np.sum(weights*y_train[indexes])/np.sum(weights)) # каждый из этих соседей равен 0 либо 1. Если 1, то вес будет учтен при умножении, иначе нет.\n",
        "      y_pred = np.array(y_pred)\n",
        "\n",
        "    return y_pred"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Создаем выборку размера 10000 с помощью встроенной в sklearn функции"
      ],
      "metadata": {
        "id": "UHFK_2LjPw1T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = make_classification(n_samples=10000, n_features=10, n_informative=7, random_state=42)\n",
        "X = pd.DataFrame(X)\n",
        "y = pd.Series(y)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y)"
      ],
      "metadata": {
        "id": "FSubqdd8Kn7c"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Обучим нашу модель и спрогнозируем классы для тех же данных. Затем обучим встроенную в sklearn модель и сравним их прогнозы."
      ],
      "metadata": {
        "id": "m2pZUbYMP2HB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = MyKNNClf(k=3, metric = 'euclidean', weight='distance')\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "np.mean(y_pred == y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lFEB9lraIWes",
        "outputId": "434482a0-4dc2-4820-baad-a1bde0bf2b1b"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9116"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_sk = KNeighborsClassifier(3, weights='distance', metric='euclidean')\n",
        "model_sk.fit(X_train, y_train)\n",
        "y_pred_sk = model_sk.predict(X_test)\n",
        "\n",
        "np.mean(y_pred_sk==y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C4YcBDKPL3eW",
        "outputId": "a22db2ed-bf02-49f5-8c0b-4fa8988f8154"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9116"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(y_pred==y_pred_sk).sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IMmzxz9pQdAX",
        "outputId": "d24642f3-fd9e-4fe7-845c-f4f541b6fd9c"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2500"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = MyKNNClf(k=3)\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "np.mean(y_pred == y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GGr7kz1YQK78",
        "outputId": "f1adcb86-f282-454c-b3a8-51ed70480b1e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9116"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_sk = KNeighborsClassifier(3)\n",
        "model_sk.fit(X_train, y_train)\n",
        "y_pred_sk = model_sk.predict(X_test)\n",
        "\n",
        "np.mean(y_pred_sk==y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ol3e7u0OQN8o",
        "outputId": "84a596a5-bb7d-43a0-e074-1239b0473743"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9116"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(y_pred==y_pred_sk).sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hXx3JPwwNJAA",
        "outputId": "20c7f433-d00a-4247-bdf8-059f97e663fe"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2498"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Как мы видим, данная реализация дает практически идентичный встроенной модели результат, хотя и проигрывает ей по времени из-за некоторых не совсем оптимальных решений внутри кода. Поскольку модель показывает сопоставимую точность и при этом поддерживает несколько вариаций метрик и весов, я считаю свою реализацю успешной."
      ],
      "metadata": {
        "id": "tA-wvFABP7c4"
      }
    }
  ]
}